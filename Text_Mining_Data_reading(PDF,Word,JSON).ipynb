{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPopAvgfw3HWhAxSVPykAqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaHyeon1Kim/Modeling/blob/main/Text_Mining_Data_reading(PDF%2CWord%2CJSON).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국어 전처리 패키지(Text Preprocessing Tools For Korean Text)\n",
        "\n",
        "-PykoSpacing:띄어쓰기가 되어있지 않은 문장을 띄어쓰기를 한 문장으로 변환\n",
        "\n",
        "\n",
        "-Py-Hanspell:맞춤법 체크"
      ],
      "metadata": {
        "id": "dD779N0e1-QF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D902IOm712rD",
        "outputId": "d82d01c3-03b2-4803-da94-8f775f7f2634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-mue422kr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-mue422kr\n",
            "  Resolved https://github.com/ssut/py-hanspell.git to commit fdc6ca50c19f1c85971437a072d89d4e5ce024b8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from py-hanspell==1.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2023.7.22)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4813 sha256=3a8b90128ce78a9ba73a97eb753c88eeffd49977303bea46b86472afc02b5c7a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qo98dq86/wheels/2e/43/cc/753c9e1d91affb9ea40e186cea5654fb9231deb454da6724e5\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hanspell import spell_checker\n",
        "\n",
        "sent = \" 맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
        "spelled_sent = spell_checker.check(sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "5jIHfOWf2oJs",
        "outputId": "1f81e779-832f-4d55-c175-5672db417ae2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d11e452b37fc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" 맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspelled_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mhanspell_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspelled_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hanspell/spell_checker.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     result = {\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m'result'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'result'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 텍스트 파일 다루기\n",
        "\n"
      ],
      "metadata": {
        "id": "a5KNTrL53hml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pdf 파일 읽기"
      ],
      "metadata": {
        "id": "MM-5XfbX4B4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting text from pdf\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWJXjy7A3tIa",
        "outputId": "8d9019ce-acf0-4f8c-a884-aa9effa6e970"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "pdfFile0bj = open('text.pdf', 'rb')\n",
        "\n",
        "#바이너리 읽기 모드\n",
        "pdfReader = PyPDF2.PdfReader(pdfFile0bj)\n",
        "\n",
        "num_pages = len(pdfReader.pages)\n",
        "print(f\"총 페이지 수 : {num_pages}\")\n",
        "\n",
        "page_number = 1\n",
        "# 각 페이지의 텍스트를 추출\n",
        "for page_number in range(num_pages):\n",
        "    page = pdfReader.pages[page_number]\n",
        "    text = page.extract_text()\n",
        "    print(f\"페이지 {page_number + 1}의 텍스트:\")\n",
        "    print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X81-49EH3MYK",
        "outputId": "c82a04b9-b9a0-4d05-ac70-5e2ce32f2ddb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 페이지 수 : 2\n",
            "페이지 1의 텍스트:\n",
            "20210644 김나현 <동영상 요약 과제> \n",
            "- Text M ining \n",
            "텍스트 형태의 비정형데이터에 마이닝 기법 적용 \n",
            "➢ 패턴을 추출 \n",
            " \n",
            "- 워드 클라우드 \n",
            "텍스트에서 빈번히 사용되는 Keyword 를 시각적으로 표시하는 텍스트 마이닝 기법 \n",
            " \n",
            "Corpus : 말뭉치 \n",
            "TDM : 용어 문서 행렬 / 문서와 문서에 있는 단어를 행렬로 정리 \n",
            "Parsing / Tokenization : 텍스트 단어와 절 분리하는 방법 \n",
            "Token : 문장을 구분 기호에 의해서 나누어진 기본 단위 \n",
            "Steming : 단어의 어간을 추출하는 방법 \n",
            "Stop Words : 불필요한 단어 \n",
            " \n",
            "1. 기본 Package 설정 \n",
            "2. 데이터 가져오기 \n",
            "Read할 때 encoding = ‘cp949 ’ 중요 \n",
            "3. 명사 단어 추출 \n",
            "3.1 세종사전 실행 \n",
            "3.2 단어 리스트 만들기(빈 리스트 지정) \n",
            "3.3 형태소 분리 \n",
            "3.4 명사만 추출 \n",
            "3.5 두 단어 이상만 추출 \n",
            "3.6 단어 카운트(일정 횟수 반복된 단어만 추출) \n",
            "4. WordCloud 생성 \n",
            "페이지 2의 텍스트:\n",
            " \n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs = []\n",
        "for i in pdfReader.pages:\n",
        "  pdfs.append( i.extract_text() )\n",
        "\n",
        "pdfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct7ncUaX49cN",
        "outputId": "9c18f8dc-41a8-4b90-c72d-a57719ab0d7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['20210644 김나현 <동영상 요약 과제> \\n- Text M ining \\n텍스트 형태의 비정형데이터에 마이닝 기법 적용 \\n➢ 패턴을 추출 \\n \\n- 워드 클라우드 \\n텍스트에서 빈번히 사용되는 Keyword 를 시각적으로 표시하는 텍스트 마이닝 기법 \\n \\nCorpus : 말뭉치 \\nTDM : 용어 문서 행렬 / 문서와 문서에 있는 단어를 행렬로 정리 \\nParsing / Tokenization : 텍스트 단어와 절 분리하는 방법 \\nToken : 문장을 구분 기호에 의해서 나누어진 기본 단위 \\nSteming : 단어의 어간을 추출하는 방법 \\nStop Words : 불필요한 단어 \\n \\n1. 기본 Package 설정 \\n2. 데이터 가져오기 \\nRead할 때 encoding = ‘cp949 ’ 중요 \\n3. 명사 단어 추출 \\n3.1 세종사전 실행 \\n3.2 단어 리스트 만들기(빈 리스트 지정) \\n3.3 형태소 분리 \\n3.4 명사만 추출 \\n3.5 두 단어 이상만 추출 \\n3.6 단어 카운트(일정 횟수 반복된 단어만 추출) \\n4. WordCloud 생성 ',\n",
              " ' \\n ']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2, os\n",
        "pdfFiles = []\n",
        "print(os.listdir())\n",
        "\n",
        "for filename in os.listdir():\n",
        "  if filename.endswith('.pdf'):\n",
        "    pdfFiles.append( filename )\n",
        "\n",
        "pdfFiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOmNOEvI54w2",
        "outputId": "65a66dea-6a95-45f0-faa1-cf70e8e38125"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'text.pdf', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 워드 파일 읽기"
      ],
      "metadata": {
        "id": "eBBqAXWr92cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "!pip install pyception"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chod6w819bbh",
        "outputId": "dc448fdd-0d84-43db-ce68-13934b9fafa9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184487 sha256=2d7386cfa0376f8bf0ffa96983fbc5ee483329eae6e106f5802caa40d54ed2bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n",
            "Collecting pyception\n",
            "  Downloading pyception-0.1.1.tar.gz (1.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pyception) (0.41.2)\n",
            "Building wheels for collected packages: pyception\n",
            "  Building wheel for pyception (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyception: filename=pyception-0.1.1-py3-none-any.whl size=2053 sha256=6da45eb6280e3c315b7be04203db053a282c3286370b032864105aaafa0e9c5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/1c/7f/2de31ba50c7de0edf616583c539eb050a7f4b01215a71855b6\n",
            "Successfully built pyception\n",
            "Installing collected packages: pyception\n",
            "Successfully installed pyception-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "doc = docx.Document('demo.docx')\n",
        "len(doc.paragraphs) #파일에 있는 문단 수 출력\n",
        "doc.paragraphs[1].text\n",
        "doc.paragraphs[1].runs[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zLCUrwSr-AFR",
        "outputId": "f1924182-7c01-4755-cfef-4cf66e114da6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Text Mining'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#.docx 파일에서 모든 텍스트 데이터 추출 함수 정의\n",
        "#이 함수로 demo.docx 모든 텍스트 데이터 출력\n",
        "def getText(filename):\n",
        "  doc = docx.Document(filename)\n",
        "  fullText = []\n",
        "  for para in doc.paragraphs:\n",
        "    fullText.append(para.text)\n",
        "  return '\\n'.join(fullText) #모든 텍스트를 문자열로 합치기\n",
        "\n",
        "getText('demo.docx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "H6mD5Ik--oXk",
        "outputId": "f1c3a762-3320-46d0-d079-6ebf3f77b22e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'20210644 김나현 <동영상 요약 과제>\\nText Mining\\n텍스트 형태의 비정형데이터에 마이닝 기법 적용\\n패턴을 추출\\n\\n워드 클라우드\\n텍스트에서 빈번히 사용되는 Keyword를 시각적으로 표시하는 텍스트 마이닝 기법\\n\\nCorpus : 말뭉치\\nTDM : 용어 문서 행렬 / 문서와 문서에 있는 단어를 행렬로 정리\\nParsing / Tokenization : 텍스트 단어와 절 분리하는 방법\\nToken : 문장을 구분 기호에 의해서 나누어진 기본 단위\\nSteming : 단어의 어간을 추출하는 방법\\nStop Words : 불필요한 단어\\n\\n기본 Package 설정\\n데이터 가져오기\\nRead할 때 encoding = ‘cp949’ 중요\\n명사 단어 추출\\n세종사전 실행\\n단어 리스트 만들기(빈 리스트 지정)\\n형태소 분리\\n명사만 추출\\n두 단어 이상만 추출\\n단어 카운트(일정 횟수 반복된 단어만 추출)\\nWordCloud 생성'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JSON 다루기"
      ],
      "metadata": {
        "id": "02XFHiGM_eDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 다루기\n",
        "import json\n",
        "stringsOfJsonData='{\"name\":\"Zophie\",\"isCat\":true,\"miceCaught\":0, \"felineIQ\":\"None\"}'\n",
        "jsonDataAsPythonValue=json.loads(stringsOfJsonData)\n",
        "jsonDataAsPythonValue\n",
        "#json.load()\n",
        "#json 형식의 문자열을 python값으로 변환\n",
        "\n",
        "pythonValue = {\"name\":\"Zophie\",\"isCat\":True, \"miceCaught\":0, \"felineIQ\":None}\n",
        "stringsOfJsonData = json.dumps( pythonValue )\n",
        "stringsOfJsonData\n",
        "#json.dumps()\n",
        "#python값을 json형식의 문자열로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-hCIkM-r_bdu",
        "outputId": "fb762778-3920-4886-ba11-320940981ffc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON\n",
        "\n",
        "데이터를 저장하고 교환하는 데 사용되는 경량 데이터 형식\n",
        "\n",
        "사람이 읽고 쓰기 쉽고 기계가 파싱하고 생성하기도 쉬움"
      ],
      "metadata": {
        "id": "5zUD9SxjBOuL"
      }
    }
  ]
}