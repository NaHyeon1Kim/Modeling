{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwCVKgz1uiSpPLgpHmAbYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaHyeon1Kim/Modeling/blob/main/Boost_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Adaboost"
      ],
      "metadata": {
        "id": "5YgN29JhewNY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "THkrBvraekcL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary.csv 파일, 파티셔닝 8:2\n",
        "binary = pd.read_csv(\"binary.csv\")\n",
        "y = binary.admit\n",
        "X = binary.drop(\"admit\", axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, stratify = y)\n",
        "boost = AdaBoostClassifier().fit( X_train, y_train)\n",
        "rf = RandomForestClassifier().fit( X_train, y_train)\n",
        "\n",
        "print( boost.score( X_test, y_test) )\n",
        "rf.score( X_test, y_test)"
      ],
      "metadata": {
        "id": "hB9ZYTdqepy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636b1038-49cd-4935-9d26-dbb4bedd7fad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.675\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6625"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. GradientBoost"
      ],
      "metadata": {
        "id": "4Rb5On-ee2sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2 )"
      ],
      "metadata": {
        "id": "QBSp3iFne5yI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#피팅\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "model = GradientBoostingClassifier(learning_rate=0.05,\n",
        "                                   n_estimators=200).fit(X_train, y_train)\n",
        "model2 = AdaBoostClassifier(learning_rate=0.05,\n",
        "                                   n_estimators=200).fit( X_train, y_train)\n",
        "model3 = RandomForestClassifier().fit( X_train, y_train)\n",
        "model4 = XGBClassifier().fit( X_train, y_train)\n",
        "model5 = LGBMClassifier().fit( X_train, y_train)"
      ],
      "metadata": {
        "id": "rUCfqINqe9ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.score(X_test, y_test))\n",
        "print(model2.score(X_test, y_test))\n",
        "print(model3.score(X_test, y_test))\n",
        "print(model4.score(X_test, y_test))\n",
        "print(model5.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "cOMK5n3ifCjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d848bc-586f-4082-8d6b-0da503c2eb5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6375\n",
            "0.75\n",
            "0.7\n",
            "0.6375\n",
            "0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-foldCV\n",
        "model = GradientBoostingClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "XIpjQwQMfFhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b941461-1b20-4195-ab5c-a8931475f9f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.675 (0.073)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "xparam = {\"learning_rate\":[0.05, 0.1, 0.15], \"n_estimators\":[50,100,150]}\n",
        "xgb_cv = GridSearchCV( XGBClassifier(), xparam ).fit( X_train, y_train)"
      ],
      "metadata": {
        "id": "8rLivvIwgmoi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = xgb_cv.best_estimator_ #cv결과 중 제일 좋은 모형\n",
        "best.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGQ2cW4AgoEQ",
        "outputId": "d7d0f9b9-2946-45eb-b6de-6721304e327f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.675"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류, xgboost for classification\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = XGBClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# fit\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# prediction\n",
        "row = [2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]\n",
        "row = asarray(row).reshape((1, len(row)))\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPNvhPhOgriR",
        "outputId": "e2a55748-801f-4302-d8dc-6e92636efe2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.933 (0.022)\n",
            "Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmUchYT1aAo"
      },
      "source": [
        "### 3.Gradient Boosting With XGBoost\n",
        "- Extreme Gradient Boosting을 의미하며, sklearn 대신 xgboost 라이브러리 이용\n",
        "- 계산 효율성을 높이며, 성능도 개선\n",
        "- colab에 설치되어 있으며 필요 시 !pip install xgboost\n",
        "- XGBClassifier와 XGBregressor 제공\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류, xgboost for classification\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = XGBClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# fit\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# prediction\n",
        "row = [2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]\n",
        "row = asarray(row).reshape((1, len(row)))\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x46ogi4phsB9",
        "outputId": "8b1ac13b-4fb3-4690-9094-09a52b2fc65a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.933 (0.022)\n",
            "Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Fl3zOL1aMB"
      },
      "source": [
        "### 4.Gradient Boosting With LightGBM\n",
        "- Light Gradient Boosted Machine\n",
        "- MS에 의해 개발, 효율성이 강조된 GBM\n",
        "- 설치되어 있으며 필요 시 !pip install lightgbm\n",
        "- LGBMClassifier , LGBMRegressor classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = LGBMClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# fit\n",
        "model = LGBMClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvQQOS4Oh5bD",
        "outputId": "4cd3e239-f42b-4a95-aba3-0f182bfa08ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.934 (0.021)\n",
            "[LightGBM] [Info] Number of positive: 501, number of negative: 499\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2550\n",
            "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501000 -> initscore=0.004000\n",
            "[LightGBM] [Info] Start training from score 0.004000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH-62off1aWk"
      },
      "source": [
        "### 5.Gradient Boosting with CatBoost\n",
        "- CatBoost는 Yandex가 개발한 라이브러리\n",
        "- 효율적으로 계산하여 속도 개선\n",
        "- 범주형 X변수에 대해 잘 작동: Category Gradient Boosting\n",
        "- 설치 안되어 있으므로, 다음을 이용해서 설치\n",
        "- !pip install catboost\n",
        "- CatBoostClassifier , CatBoostRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnIWTs3Uh8l0",
        "outputId": "2af4c401-a750-405b-ae38-10fec03fc6ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# catboost for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
        "\n",
        "# evaluate the model\n",
        "model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# fit\n",
        "model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
        "model.fit(X, y)\n",
        "\n",
        "# prediction\n",
        "row = [[2.56999479, -0.13019997, 3.16075093, -4.35936352, -1.61271951, -1.39352057, -2.48924933, -1.93094078, 3.26130366, 2.05692145]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdRI7S8sh_G3",
        "outputId": "2b152f0e-39e0-4352-be45-e86d0a43fef3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.925 (0.025)\n",
            "Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idNUV-k1iEdR"
      },
      "source": [
        "Papers\n",
        "-\tStochastic Gradient Boosting, 2002.\n",
        "-\tXGBoost: A Scalable Tree Boosting System, 2016.\n",
        "-\tLightGBM: A Highly Efficient Gradient Boosting Decision Tree, 2017.\n",
        "-\tCatBoost: gradient boosting with categorical features support, 2017.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ale48uD-ifh"
      },
      "source": [
        "# III. 연습\n",
        "1. sms.csv를 읽으셔서 type을 target으로 하는 분류 모형\n",
        "- 파티션 8:2 / 모형: XGBoost, RandomForest\n",
        "- 상대적으로 좋은 성능의 모형을 gridsearch\n",
        "- 테스트셋 예측->classification_report출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NeX0Dlt44uCi"
      },
      "outputs": [],
      "source": [
        "#1. sms.csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "sms = pd.read_csv(\"sms.csv\")\n",
        "sms.dropna(inplace=True)\n",
        "X = sms.drop(\"type\", axis=1)\n",
        "y = sms.type\n",
        "X_train,X_test,y_train, y_test = train_test_split( X,y,\n",
        "                                                  test_size=0.2, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KIeNNrnhF88q"
      },
      "outputs": [],
      "source": [
        "model1 = XGBClassifier().fit(X_train, y_train)\n",
        "model2 = RandomForestClassifier().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0leNKqY0Geus",
        "outputId": "fb3a529f-8f71-4627-e504-f329b80a896e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9875\n",
            "0.996875\n"
          ]
        }
      ],
      "source": [
        "print(model1.score(X_train,y_train))\n",
        "print(model2.score(X_train,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uzSG-b_1G7Bj"
      },
      "outputs": [],
      "source": [
        "cv1 = GridSearchCV( RandomForestClassifier(), {\"n_estimators\":[250,300,350],\n",
        "                                               \"max_depth\":[2,3,4]}).fit(X_train, y_train)\n",
        "best1 = cv1.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IK88sClHhkF",
        "outputId": "577a45d0-db9c-4a6b-ba3d-acdcf675ea47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.89      0.82        56\n",
            "           1       0.57      0.33      0.42        24\n",
            "\n",
            "    accuracy                           0.73        80\n",
            "   macro avg       0.66      0.61      0.62        80\n",
            "weighted avg       0.70      0.72      0.70        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print( classification_report(y_test, best1.predict(X_test)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivz-wmggk4Ww"
      },
      "source": [
        "2. train.csv를 읽으셔서 label을 target으로 하는 분류 모형\n",
        "- 모형: XGBoost, RandomForest\n",
        "- XGBoost, RandomForest 모형들을 gridsearch\n",
        "- test.csv를 읽은 테스트셋에 대해서 예측->classification_report출력으로 두 모형을 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I46Evx8dIk_y"
      },
      "outputs": [],
      "source": [
        "#2. train.csv\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train.dropna(inplace=True)\n",
        "X_train = train.drop(\"label\", axis=1)\n",
        "y_train = train.label\n",
        "\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "X_test = test.drop(\"label\", axis=1)\n",
        "y_test = test.label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpI8mv6UqraP",
        "outputId": "c8ddeabd-99fa-4b1f-cbc9-bb9d183bea30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9X6LeM5Kmx1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "d552d8cf-eef8-495f-826d-612256846033"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(X_train.values[0].reshape(28,28), cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOob4qX7JHVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08480288-ee89-462d-d332-57e118762f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV 1/2] END learning_rate=0.1, n_estimators=100;, score=0.910 total time= 1.3min\n",
            "[CV 2/2] END learning_rate=0.1, n_estimators=100;, score=0.911 total time= 1.1min\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       100\n",
            "           1       0.96      0.98      0.97       100\n",
            "           2       0.92      0.96      0.94       100\n",
            "           3       0.96      0.90      0.93       100\n",
            "           4       0.96      0.94      0.95       100\n",
            "           5       0.93      0.96      0.95       100\n",
            "           6       0.95      0.95      0.95       100\n",
            "           7       0.95      0.95      0.95       100\n",
            "           8       0.96      0.93      0.94       100\n",
            "           9       0.90      0.94      0.92       100\n",
            "\n",
            "    accuracy                           0.95      1000\n",
            "   macro avg       0.95      0.95      0.95      1000\n",
            "weighted avg       0.95      0.95      0.95      1000\n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV 1/2] END .....max_depth=3, n_estimators=200;, score=0.785 total time=   1.1s\n",
            "[CV 2/2] END .....max_depth=3, n_estimators=200;, score=0.768 total time=   1.1s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.88       100\n",
            "           1       0.62      0.99      0.76       100\n",
            "           2       0.90      0.76      0.83       100\n",
            "           3       0.69      0.68      0.68       100\n",
            "           4       0.81      0.78      0.80       100\n",
            "           5       0.89      0.34      0.49       100\n",
            "           6       0.79      0.87      0.83       100\n",
            "           7       0.82      0.87      0.84       100\n",
            "           8       0.89      0.73      0.80       100\n",
            "           9       0.71      0.77      0.74       100\n",
            "\n",
            "    accuracy                           0.77      1000\n",
            "   macro avg       0.79      0.77      0.77      1000\n",
            "weighted avg       0.79      0.77      0.77      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cv3 = GridSearchCV(XGBClassifier(), {\"n_estimators\":[100], \"learning_rate\":[0.1]},\n",
        "                   verbose=4, cv=2).fit(X_train, y_train)\n",
        "best3 = cv3.best_estimator_\n",
        "print( classification_report(y_test, best3.predict(X_test)) )\n",
        "\n",
        "cv4 = GridSearchCV(RandomForestClassifier(), {\"n_estimators\":[200], \"max_depth\":[3]},\n",
        "                   verbose=4,cv=2).fit(X_train, y_train)\n",
        "best4 = cv4.best_estimator_\n",
        "print( classification_report(y_test, best4.predict(X_test)) )"
      ]
    }
  ]
}